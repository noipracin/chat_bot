import json
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline

def train_model():
    """–û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏–π"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    with open('intents.json', 'r', encoding='utf-8') as f:
        intents = json.load(f)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    texts = []
    labels = []
    
    for intent, examples in intents.items():
        for example in examples:
            texts.append(example)
            labels.append(intent)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = Pipeline([
        ('tfidf', TfidfVectorizer()),
        ('svc', SVC(probability=True))
    ])
    
    model.fit(texts, labels)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    joblib.dump(model, 'intent_model.pkl')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –æ—Ç–¥–µ–ª—å–Ω–æ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    vectorizer = TfidfVectorizer()
    vectorizer.fit(texts)
    joblib.dump(vectorizer, 'vectorizer.pkl')
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
    print(f"üìä –û–±—É—á–µ–Ω–æ –Ω–∞ {len(texts)} –ø—Ä–∏–º–µ—Ä–∞—Ö")
    print(f"üéØ –ù–∞–º–µ—Ä–µ–Ω–∏—è: {list(intents.keys())}")

if __name__ == '__main__':
    train_model()